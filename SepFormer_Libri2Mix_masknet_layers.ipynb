{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a8117a-e091-4f7f-8131-76f78fdf5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import fire\n",
    "from typing import Dict, List, Any, Union, Sequence, Tuple\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "from dataset_noav_8k_2 import MyDatasets, collate_LibriMix\n",
    "from dual_path import SepformerWrapper\n",
    "#from losses import SI_SNR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio import datasets\n",
    "from scipy.io.wavfile import read, write\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "#from mir_eval.separation import bss_eval_sources\n",
    "import mir_eval\n",
    "from itertools import permutations\n",
    "from dataclasses import dataclass, field, fields\n",
    "from torchaudio.transforms import MelScale\n",
    "from typing import List, Type, Any, Callable, Optional, Union\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device( 'cpu' )\n",
    "num_workers = 0 if device == torch.device('cpu') else 8\n",
    "\n",
    "print( num_workers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53b83b9-5a5f-4f46-90c0-aaa4d8d162e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13900\n",
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "train_ds = MyDatasets( \"train\" )\n",
    "train_loader = DataLoader( train_ds, batch_size=1,shuffle=True, num_workers=num_workers, collate_fn = collate_LibriMix)\n",
    "print( len(train_loader))\n",
    "val_ds = MyDatasets( \"valid\" )\n",
    "val_loader = DataLoader( val_ds, batch_size=1,shuffle=False, num_workers=num_workers, collate_fn = collate_LibriMix)\n",
    "print( len(val_loader))\n",
    "test_ds = MyDatasets( \"test\" )\n",
    "test_loader = DataLoader( test_ds, batch_size=1,shuffle=False, num_workers=num_workers, collate_fn = collate_LibriMix)\n",
    "print( len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cf90f5-2494-41ed-b9e2-e7f002cf6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2norm(mat, keepdim=False):\n",
    "    return torch.norm(mat, dim=-1, keepdim=keepdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54cff602-061f-40cd-ab60-2220755d62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class STFTBase(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Base layer for (i)STFT\n",
    "    NOTE:\n",
    "        1) Recommend sqrt_hann window with 2**N frame length, because it \n",
    "           could achieve perfect reconstruction after overlap-add\n",
    "        2) Now haven't consider padding problems yet\n",
    "    \"\"\"\n",
    "    device: torch.device\n",
    "    frame_length: int\n",
    "    frame_shift: int\n",
    "    window: str\n",
    "    K: torch.nn.Parameter = field(init=False)\n",
    "    num_bins: int = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super(STFTBase, self).__init__()  # Initialize the torch.nn.Module base class\n",
    "        K = self._init_kernel(self.frame_length, self.frame_shift)\n",
    "        self.K = torch.nn.Parameter(K, requires_grad=False).to(self.device)\n",
    "        self.num_bins = self.K.shape[0] // 2\n",
    "    \n",
    "    def _init_kernel(self, frame_len, frame_hop):\n",
    "        # FFT points\n",
    "        N = frame_len\n",
    "        # window\n",
    "        if self.window == 'hann':\n",
    "            W = torch.hann_window(frame_len)\n",
    "        if N//4 == frame_hop:\n",
    "            const = (2/3)**0.5       \n",
    "            W = const*W\n",
    "        elif N//2 == frame_hop:\n",
    "            W = W**0.5\n",
    "        S = 0.5 * (N * N / frame_hop)**0.5\n",
    "        \n",
    "        # Updated FFT calculation for efficiency\n",
    "        K = torch.fft.rfft(torch.eye(N) / S, dim=1)[:frame_len]\n",
    "        K = torch.stack((torch.real(K), torch.imag(K)), dim=2)\n",
    "        K = torch.transpose(K, 0, 2) * W # 2 x N/2+1 x F\n",
    "        K = torch.reshape(K, (N + 2, 1, frame_len)) # N+2 x 1 x F\n",
    "        return K\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return (f\"window={self.window}, stride={self.frame_shift}, \" +\n",
    "                f\"kernel_size={self.K.shape[0]}x{self.K.shape[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6a9396-4921-4747-bb52-e1f10a68b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@logger_wraps()\n",
    "@dataclass(slots=True)\n",
    "class STFT(STFTBase):\n",
    "    \"\"\"\n",
    "    Short-time Fourier Transform as a Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, cplx=False):\n",
    "        \"\"\"\n",
    "        Accept (single or multiple channel) raw waveform and output magnitude and phase\n",
    "        args\n",
    "            x: input signal, N x C x S or N x S\n",
    "        return\n",
    "            m: magnitude, N x C x F x T or N x F x T\n",
    "            p: phase, N x C x F x T or N x F x T\n",
    "        \"\"\"\n",
    "        if x.dim() not in [2, 3]:\n",
    "            #raise RuntimeError(\n",
    "            #    \"{} expect 2D/3D tensor, but got {:d}D signal\".format(\n",
    "            #        self.__name__, x.dim()))\n",
    "            raise RuntimeError(\n",
    "                \"expect 2D/3D tensor, but got {:d}D signal\".format(\n",
    "                     x.dim()))\n",
    "        # if N x S, reshape N x 1 x S\n",
    "        N_frame = ceil(x.shape[-1] / self.frame_shift)\n",
    "        len_padded = N_frame * self.frame_shift\n",
    "        if x.dim() == 2:\n",
    "            \n",
    "            x = torch.cat((x, torch.zeros(x.shape[0], len_padded-x.shape[-1], device=x.device)), dim=-1)\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # N x 2F x T\n",
    "            c = torch.nn.functional.conv1d(x, self.K, stride=self.frame_shift, padding=0)\n",
    "            # N x F x T\n",
    "            r, i = torch.chunk(c, 2, dim=1)\n",
    "        else:        \n",
    "            x = torch.cat((x, torch.zeros(x.shape[0], x.shape[1], len_padded-x.shape[-1])), dim=-1)\n",
    "            N, C, S = x.shape\n",
    "            x = x.reshape(N * C, 1, S)\n",
    "            # NC x 2F x T\n",
    "            c = torch.nn.functional.conv1d(x, self.K, stride=self.frame_shift, padding=0)\n",
    "            # N x C x 2F x T\n",
    "            c = c.reshape(N, C, -1, c.shape[-1])\n",
    "            # N x C x F x T\n",
    "            r, i = torch.chunk(c, 2, dim=2)\n",
    "\n",
    "        if cplx:\n",
    "            return r, i\n",
    "        m = (r**2 + i**2 + 1.0e-10)**0.5\n",
    "        p = torch.atan2(i, r)\n",
    "        return m, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2d336a-1fdb-4da5-9593-6b7a0bd403b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@logger_wraps()\n",
    "@dataclass(slots=True)\n",
    "class PIT_SISNR_mag:\n",
    "    device: torch.device\n",
    "    frame_length: int\n",
    "    frame_shift: int\n",
    "    window: str\n",
    "    num_stages: int\n",
    "    num_spks: int\n",
    "    scale_inv: bool\n",
    "    mel_opt: bool\n",
    "    \n",
    "    \n",
    "    stft: List[Any] = field(init=False)\n",
    "    mel_fb: Callable[[torch.Tensor], torch.Tensor] = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.stft = [STFT(self.device, self.frame_length, self.frame_shift, self.window) for _ in range(self.num_stages)]\n",
    "        self.mel_fb = MelScale(n_mels=80, sample_rate=16000, n_stft=int(self.frame_length / 2) + 1).to(self.device) if self.mel_opt else lambda x: x\n",
    "\n",
    "    def __repr__(self):\n",
    "        # __init__\n",
    "        class_name = self.__class__.__name__\n",
    "        init_fields = [f for f in fields(self) if f.init]\n",
    "        field_strs = [f\"{field.name}={getattr(self, field.name)!r}\" for field in init_fields]\n",
    "\n",
    "        # __post_init__\n",
    "        stft_repr = f\"stft = [STFT instance for {len(self.stft)} layers]\"\n",
    "        mel_fb_repr = \"mel_fb = MelScale\" if self.mel_opt else \"mel_fb=Identity\"\n",
    "        post_init_reprs = [stft_repr, mel_fb_repr]\n",
    "\n",
    "        return f\"<{class_name}({', '.join(field_strs + post_init_reprs)})>\"\n",
    "    \n",
    "    #def __call__(self, **kwargs):\n",
    "    def __call__(self,  targets, estims, idx ):\n",
    "        #estims = kwargs['estims']\n",
    "        #idx = kwargs['idx']\n",
    "        #num_utts = estims.size(0) * estims.size(1)\n",
    "        num_utts = estims.size(1)\n",
    "        #idx = 0\n",
    "        #targets = targets.view( targets.size(0) * targets.size(1), -1 ).cpu()\n",
    "        #estims = estims.view( estims.size(0) * estims.size(1), -1 ) \n",
    "        #input_sizes = kwargs[\"input_sizes\"].to(self.device)\n",
    "        #targets = [t.to(self.device) for t in kwargs[\"target_attr\"]]\n",
    "        \n",
    "        def _STFT_Mag_SDR_loss(permute, eps=1.0e-12):\n",
    "            loss_for_permute = []\n",
    "            for s, t in enumerate(permute):\n",
    "                mix = estims[s]\n",
    "                src = targets[t]\n",
    "                mix_zm = mix - torch.mean(mix, dim=-1, keepdim=True)\n",
    "                src_zm = src - torch.mean(src, dim=-1, keepdim=True)\n",
    "                if self.scale_inv:\n",
    "                    scale = torch.sum(mix_zm * src_zm, dim=-1, keepdim=True) / (l2norm(src_zm, keepdim=True)**2 + eps)\n",
    "                    src_zm = torch.clamp(scale, min=1e-2) * src_zm\n",
    "                mix_zm = self.stft[idx](mix_zm.to(self.device))[0]\n",
    "                src_zm = self.stft[idx](src_zm.to(self.device))[0]\n",
    "                if self.mel_opt:\n",
    "                    mix_zm = self.mel_fb(mix_zm)\n",
    "                    src_zm = self.mel_fb(src_zm)\n",
    "                utt_loss = -20 * torch.log10(eps + l2norm(l2norm((src_zm))) / (l2norm(l2norm(mix_zm - src_zm)) + eps))                \n",
    "                loss_for_permute.append(utt_loss)\n",
    "            return sum(loss_for_permute)\n",
    "        \n",
    "        pscore = torch.stack([_STFT_Mag_SDR_loss(p) for p in permutations(range(self.num_spks))])\n",
    "        min_perutt, _ = torch.min(pscore, dim=0)\n",
    "        #num_utts = input_sizes.shape[0]\n",
    "        return torch.sum(min_perutt) / num_utts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ffc992-cb64-4b5b-a8b5-4f2369dec951",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spks = 2\n",
    "pit_sisnr_mag = PIT_SISNR_mag(     \n",
    "    device = device,\n",
    "    frame_length = 512,\n",
    "    frame_shift = 128,\n",
    "    window = 'hann',\n",
    "    num_stages = 4,\n",
    "    num_spks = 2,\n",
    "    scale_inv = True,\n",
    "    mel_opt = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e32089-3c3c-401d-888d-dd1c1e6b57c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(74.7565, device='cuda:0')\n",
      "tensor(74.7565, device='cuda:0')\n",
      "tensor(74.7565, device='cuda:0')\n",
      "tensor(74.7565, device='cuda:0')\n",
      "tensor(299.0260, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn( (2,1, 32000))\n",
    "y = torch.randn( (2,1, 32000) )\n",
    "\n",
    "loss11 = pit_sisnr_mag( x, y, 0 )\n",
    "loss12 = pit_sisnr_mag( x, y, 1 )\n",
    "loss13 = pit_sisnr_mag( x, y, 2 )\n",
    "loss14 = pit_sisnr_mag( x, y, 3 )\n",
    "#loss13 = pit_sisnr_mag( x, y, 2 )\n",
    "loss1 = loss11 + loss12 + loss13 + loss14\n",
    "\n",
    "print( loss11 )\n",
    "print( loss12 )\n",
    "print( loss13 )\n",
    "print( loss14 )\n",
    "print( loss1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7daf8890-7277-47aa-9c75-e75acdd079ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@logger_wraps()\n",
    "@dataclass(slots=True)\n",
    "class PIT_SISNR_time:\n",
    "    device: torch.device\n",
    "    num_spks: int\n",
    "    scale_inv: bool\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        init_fields = [f for f in fields(self) if f.init]\n",
    "        field_strs = [f\"{field.name}={getattr(self, field.name)!r}\" for field in init_fields]\n",
    "        return f\"<{class_name}({', '.join(field_strs)})>\"\n",
    "    \n",
    "    #def __call__(self, **kwargs):\n",
    "    def __call__(self, targets, estims):\n",
    "        #estims = kwargs['estims']\n",
    "        #input_sizes = kwargs[\"input_sizes\"].to(self.device)\n",
    "        #num_utts = estims.size(0) * estims.size(1)\n",
    "        num_utts =  estims.size(1)\n",
    "        #targets = [target.to(self.device) for target in kwargs[\"target_attr\"]]\n",
    "        \n",
    "        def _SDR_loss(permute, eps=1.0e-8):\n",
    "            loss_for_permute = []\n",
    "            for s, t in enumerate(permute):\n",
    "                mix = estims[s]\n",
    "                src = targets[t]\n",
    "                \n",
    "                mix_zm = mix - torch.mean(input=mix, dim=-1, keepdim=True)\n",
    "                src_zm = src - torch.mean(input=src, dim=-1, keepdim=True)\n",
    "                if self.scale_inv:\n",
    "                    scale_factor = torch.sum(mix_zm * src_zm, dim=-1, keepdim=True) / (l2norm(src_zm, keepdim=True)**2 + eps)\n",
    "                    src_zm_scale = scale_factor * src_zm\n",
    "                \n",
    "                utt_loss = - 20 * torch.log10(eps + l2norm(src_zm_scale) / (l2norm(mix_zm - src_zm_scale) + eps))\n",
    "                utt_loss = torch.clamp(utt_loss, min=-30)\n",
    "                \n",
    "                loss_for_permute.append(utt_loss)\n",
    "            return sum(loss_for_permute)\n",
    "        \n",
    "        pscore = torch.stack([_SDR_loss(p) for p in permutations(range(self.num_spks))])\n",
    "        min_perutt, _ = torch.min(pscore, dim=0)\n",
    "        #num_utts = input_sizes.shape[0]\n",
    "        return torch.sum(min_perutt) / num_utts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc6a480-0bf7-48d7-982a-f25eeed8d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_sisnr_time = PIT_SISNR_time(\n",
    "    device = device,\n",
    "    num_spks = 2,\n",
    "    scale_inv = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5d7a07-6771-488c-86fd-a046a5ba1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@logger_wraps()\n",
    "@dataclass(slots=True)\n",
    "class PIT_SISNRi:\n",
    "    device: torch.device\n",
    "    num_spks: int\n",
    "    scale_inv: bool\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        init_fields = [f for f in fields(self) if f.init]\n",
    "        field_strs = [f\"{field.name}={getattr(self, field.name)!r}\" for field in init_fields]\n",
    "        return f\"<{class_name}({', '.join(field_strs)})>\"\n",
    "    \n",
    "    #def __call__(self, **kwargs):\n",
    "    def __call__(self, targets, estims, mix):\n",
    "        #estims = kwargs['estims']\n",
    "        #input_sizes = kwargs[\"input_sizes\"].to(self.device)\n",
    "        #num_utts = estims.size(0) * estims.size(1)\n",
    "        num_utts = estims.size(1)\n",
    "        #targets = [target.to(self.device) for target in kwargs[\"target_attr\"]]\n",
    "        #estims = kwargs['estims']\n",
    "        #input_sizes = kwargs[\"input_sizes\"].to(self.device)\n",
    "        #targets = [t.to(self.device) for t in kwargs[\"target_attr\"]]\n",
    "        #input = kwargs['mixture'].to(self.device)\n",
    "        #input_zm = input - torch.mean(input, dim=-1, keepdim=True)\n",
    "        input = mix\n",
    "        input_zm = input - torch.mean( input, dim=-1, keepdim=True)\n",
    "        #eps = kwargs['eps']\n",
    "        eps=1.0e-15 \n",
    "        \n",
    "        def _SDR_loss(permute):\n",
    "            #print( \"permute:\", permute )\n",
    "            #print( \"permute device:\", permute.device )\n",
    "            #loss_for_permute = []\n",
    "            loss_for_permute = torch.tensor( [], device=device )\n",
    "            for s, t in enumerate(permute):\n",
    "                est = estims[s]\n",
    "                src = targets[t]\n",
    "                est_zm = est - torch.mean(est, dim=-1, keepdim=True)\n",
    "                src_zm = src - torch.mean(src, dim=-1, keepdim=True)\n",
    "                #print( \"est_zm device:\", est_zm.device )\n",
    "                #print( \"src_zm device:\", src_zm.device )\n",
    "                if self.scale_inv:\n",
    "                    src_zm_s = torch.sum(est_zm * src_zm, dim=-1, keepdim=True) / (l2norm(src_zm, keepdim=True)**2 + eps) * src_zm\n",
    "                \n",
    "                utt_loss_est = 20 * torch.log10(eps + l2norm(src_zm_s) / (l2norm(est_zm - src_zm_s) + eps))\n",
    "                if self.scale_inv:\n",
    "                    src_zm_x = torch.sum(input_zm * src_zm, dim=-1, keepdim=True) / (l2norm(src_zm, keepdim=True)**2 + eps) * src_zm\n",
    "                utt_loss_in = 20 * torch.log10(eps + l2norm(src_zm_x) / (l2norm(input_zm - src_zm_x) + eps))\n",
    "                #print( \"utt_loss_est device:\", utt_loss_est.device )\n",
    "                #print( \"utt_loss_in device:\", utt_loss_in.device )\n",
    "                #loss_for_permute.append(utt_loss_est - utt_loss_in)\n",
    "                loss_for_permute = torch.cat( [loss_for_permute, utt_loss_est-utt_loss_in], dim = 0 )\n",
    "            #loss_for_permute = torch.tensor( loss_for_permute ).to(device)\n",
    "            #return torch.tensor(loss_for_permute) \n",
    "            return loss_for_permute \n",
    "            #return loss_for_permute.detach().clone().requires_grad_(True)\n",
    "        \n",
    "        pscore = torch.stack([_SDR_loss(torch.tensor(p).to(device)) for p in permutations(range(self.num_spks))],dim=0)\n",
    "        #print( \"pscore device:\", pscore.device )\n",
    "        min_perutt, min_idx = torch.max(pscore.sum(-1), dim=0)\n",
    "        #print( \"min_perutt device:\", min_perutt.device )\n",
    "        #num_utts = input_sizes.shape[0]\n",
    "        return torch.sum(min_perutt) / num_utts, pscore[min_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1841f01-816f-432c-a977-41cc9cc886c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_sisnri = PIT_SISNRi(\n",
    "    device = device,\n",
    "    num_spks = 2,\n",
    "    scale_inv = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "683f6efe-4a44-4117-99c6-7b446aae52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _SDR( mix, targets, estims, num_spks ):\n",
    "    targets = targets.reshape( targets.size(0) * targets.size(1), -1 ).cpu().data.numpy()\n",
    "    estims = estims.reshape( estims.size(0) * estims.size(1), -1 ).cpu().data.numpy() \n",
    "    mix1 = mix[None,:,:].expand( num_spks, mix.size(0), mix.size(1) )\n",
    "    mix2 = mix1.reshape( num_spks * mix.size(0), -1 ).cpu().data.numpy() \n",
    "    mix = mix[None,:,:].expand( num_spks, mix.size(0), mix.size(1) ).reshape( num_spks * mix.size(0), -1 ).cpu().data.numpy() \n",
    "    \n",
    "    min_perutt_out, _, _, _ = mir_eval.separation.bss_eval_sources(targets, estims)\n",
    "    #print( min_perutt_out )\n",
    "    min_perutt_in, _, _, _ = mir_eval.separation.bss_eval_sources(targets, mix)\n",
    "    #print( min_perutt_in )\n",
    "    \n",
    "    num_utts = len( mix )\n",
    "    return np.sum(min_perutt_out - min_perutt_in) / num_utts, min_perutt_out - min_perutt_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a394a209-bd9a-46b5-affd-af9cecd3e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')\n",
    "model = SepformerWrapper()\n",
    "model = model.to(device)\n",
    "optimizer = Adam( model.parameters(), lr = 1.5e-4 )\n",
    "#criterion = SI_SNR()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience = 2 )\n",
    "num_spks = 2\n",
    "frame_length = 512\n",
    "frame_shift = 128\n",
    "window = 'hann'\n",
    "num_stages = 4\n",
    "scale_inv = True\n",
    "mel_opt = False\n",
    "pit_sisnr_mag = PIT_SISNR_mag(     \n",
    "    device = device,\n",
    "    frame_length = frame_length,\n",
    "    frame_shift = frame_shift,\n",
    "    window = window,\n",
    "    num_stages = num_stages,\n",
    "    num_spks = num_spks,\n",
    "    scale_inv = scale_inv,\n",
    "    mel_opt = mel_opt\n",
    "    )\n",
    "pit_sisnr_time = PIT_SISNR_time(\n",
    "    device = device,\n",
    "    num_spks = num_spks,\n",
    "    scale_inv = scale_inv\n",
    ")\n",
    "pit_sisnri = PIT_SISNRi(\n",
    "    device = device,\n",
    "    num_spks = num_spks,\n",
    "    scale_inv = scale_inv\n",
    ")\n",
    "# これは関数。SDR, _ = _SDR( mix, targets, estims, num_spks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d08f19-d455-4372-ba58-1a9df2587933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113922/3987928468.py:8: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  min_perutt_out, _, _, _ = mir_eval.separation.bss_eval_sources(targets, estims)\n",
      "/tmp/ipykernel_113922/3987928468.py:10: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  min_perutt_in, _, _, _ = mir_eval.separation.bss_eval_sources(targets, mix)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(83.5468, device='cuda:0')\n",
      "tensor(79.9074, device='cuda:0')\n",
      "tensor(79.9074, device='cuda:0')\n",
      "tensor(79.9074, device='cuda:0')\n",
      "tensor(79.9074, device='cuda:0')\n",
      "tensor(31.1788, device='cuda:0')\n",
      "cuda:0\n",
      "cuda:0\n",
      "0.36761789217849383\n"
     ]
    }
   ],
   "source": [
    "mix = torch.rand( ( 1, 32000 ), device = device )\n",
    "targets = torch.randn( (2, 1, 32000 ), device = device )\n",
    "estims = torch.randn( (2, 1, 32000 ), device = device )\n",
    "#mix = torch.rand( ( 2, 32000 ), device = device )\n",
    "#targets = torch.randn( (2, 2, 32000 ), device = device )\n",
    "#estims = torch.randn( (2, 2, 32000 ), device = device )\n",
    "\n",
    "#SDR, _ = _SDR( mix, targets, estims, num_spks )\n",
    "#loss1 = criterion(targets, estims)\n",
    "loss1 = pit_sisnr_time( targets, estims )\n",
    "loss21 = pit_sisnr_mag( targets, estims, 0 )\n",
    "loss22 = pit_sisnr_mag( targets, estims, 1 )\n",
    "loss23 = pit_sisnr_mag( targets, estims, 2 )\n",
    "loss24 = pit_sisnr_mag( targets, estims, 3 )\n",
    "loss3, plus = pit_sisnri( targets, estims, mix )\n",
    "sdr, _ = _SDR( mix, targets, estims, num_spks )\n",
    "\n",
    "print( loss1 )\n",
    "print( loss21 )\n",
    "print( loss22 )\n",
    "print( loss23 )\n",
    "print( loss24 )\n",
    "print( loss3 )\n",
    "print( device )\n",
    "print( loss3.device )\n",
    "print( sdr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f6238f-4a48-4b94-908c-44a75d649cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 32000, 2])\n"
     ]
    }
   ],
   "source": [
    "pred_wav_layers = model( mix )\n",
    "\n",
    "print( pred_wav_layers.size() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33805e71-8ca7-426d-bcb2-6c66cba9de0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bffa2f1b4be4979aab9828606b144f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113922/3987928468.py:8: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  min_perutt_out, _, _, _ = mir_eval.separation.bss_eval_sources(targets, estims)\n",
      "/tmp/ipykernel_113922/3987928468.py:10: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  min_perutt_in, _, _, _ = mir_eval.separation.bss_eval_sources(targets, mix)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 0 train sisnri loss: 7.239302484248396  sdr: 7.5784643107449\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ecea3e6e3a471a873fa04af45126d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 val sisnri loss: 8.030588511427244  sdr: 8.479904782104674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae4cbd2a80b425f902739c120288ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 0 test sisnri loss: 7.730380677722395  sdr: 8.178212767270002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1004187144964350b3870832253b6827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 1 train sisnri loss: 9.226973466374677  sdr: 9.510773866904923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b59365ef4d45a69e826640e09f77dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 val sisnri loss: 9.837368381207188  sdr: 10.231234453297999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cfd931b01a4d2889140ee06cf79a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 1 test sisnri loss: 9.635624479730923  sdr: 10.033044394771833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f24625e54e492e903347fb1d23c775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 2 train sisnri loss: 11.017513997710223  sdr: 11.267923372224969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5e8d6fd8cc4bb199b678a3d0ef0833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 val sisnri loss: 11.380515728277464  sdr: 11.78331854646249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf1fffe218e42cbb5b7877e58a060d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 2 test sisnri loss: 11.106311268731952  sdr: 11.528127476656646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0da9993036489382d73a2b91218732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 3 train sisnri loss: 12.57184047207933  sdr: 12.805431790030973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821fe497f2e24327abd0125d448d41ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 val sisnri loss: 12.616835375924905  sdr: 13.020324239660265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07712ed28f541b49b75034ecde13ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 3 test sisnri loss: 12.472764425923428  sdr: 12.879614995253412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621747ca639e42b69d144dd3136e3031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 4 train sisnri loss: 13.72124180725903  sdr: 13.931387780352141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b087c88c715142968c7ed4ab9d8fc031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 val sisnri loss: 13.408919490774473  sdr: 13.850093914984983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ee3277e0dd49a88638804d283c051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 4 test sisnri loss: 13.190306102544069  sdr: 13.621359821876075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817d7d1d888d45908946f7b2f56bafbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 5 train sisnri loss: 14.290421241250613  sdr: 14.489045469006706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadeda5dd7714eaf9416b936a25fd3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 val sisnri loss: 13.980664086312055  sdr: 14.393553693547217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b0a240572549968f988b0a7d302765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 5 test sisnri loss: 13.674984008078773  sdr: 14.0975008112316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9acbc65f124a689afb612645f464e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 6 train sisnri loss: 14.893316152489229  sdr: 15.076259802349757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a9f48f2fe94418b43482dee53c135a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 val sisnri loss: 14.135446846654018  sdr: 14.589863259236187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738bdc7a512e48dbafee3a9577e1a075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 6 test sisnri loss: 13.89964544300735  sdr: 14.336363410643084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0838335a8740e2bb7dde34380c1d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 7 train sisnri loss: 15.445762196259318  sdr: 15.609163032246958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12ad91e10854b569a01376d786cd4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 val sisnri loss: 14.996027999177574  sdr: 15.387114511213365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4afff8a07b4550a1786352cb965561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 7 test sisnri loss: 14.612842641423146  sdr: 15.01751935551529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62acd23a1604c7296e8d2ede639bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 8 train sisnri loss: 15.908737356283254  sdr: 16.060840772238013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7c34fdbc984f54af86298d8acf14cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 val sisnri loss: 15.117382384429375  sdr: 15.535613605720338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94711402dac4e80b1af92cb9a4a4e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 8 test sisnri loss: 14.74218484172225  sdr: 15.155095781081734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e6b7fe6759482e9b8e9c0fa8e93cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015\n",
      "epoch: 9 train sisnri loss: 16.399549388063253  sdr: 16.53004396877334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1266992e1ab641b989c4bdc4a746f496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 val sisnri loss: 15.506569648226103  sdr: 15.911527003930502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8370a26402b4d59ba88180f67bec3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file was wrote.\n",
      "epoch: 9 test sisnri loss: 15.172893245607614  sdr: 15.578649943662189\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "best_val_loss = 1e9\n",
    "\n",
    "for epoch in range( num_epochs ):\n",
    "    total_sisnri = 0\n",
    "    total_sdr = 0\n",
    "    alpha = 0.4 * 0.8**(1+(epoch-101)//5) if epoch > 100 else 0.4\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader),\n",
    "              total=len(train_loader)) as pbar:\n",
    "        for step, (mixture, source) in pbar:\n",
    "            mixture, source = mixture.to(device), source.to(device)\n",
    "            #print( \"size of mixture:\", mixture.size() )\n",
    "            #print( \"size of source:\", source.size() )\n",
    "            pred_wav_layers = model(mixture)\n",
    "            #pred_wav = pred_wav.permute( 2, 0, 1 )\n",
    "            pred_wav_layers = pred_wav_layers.permute( 0, 3, 1, 2 )\n",
    "            #print( \"pred_wav size(): \", pred_wav.size() )\n",
    "            #print( \"size of pred_wav:\", pred_wav.size() )\n",
    "            loss1 = pit_sisnr_time( source, pred_wav_layers[-1] )\n",
    "            #loss21 = pit_sisnr_mag( source, pred_wav_layers[0], 0 )\n",
    "            #loss22 = pit_sisnr_mag( source, pred_wav_layers[1], 1 )\n",
    "            #loss23 = pit_sisnr_mag( source, pred_wav_layers[2], 2 )\n",
    "            #loss24 = pit_sisnr_mag( source, pred_wav, 3 )\n",
    "            loss2i = []\n",
    "            for idx, pred_wav_layer in enumerate( pred_wav_layers ):\n",
    "                loss2i.append( pit_sisnr_mag( source, pred_wav_layer, idx ) )\n",
    "            loss2 = torch.mean( torch.stack(loss2i) / num_spks )\n",
    "            loss3, _ = pit_sisnri( source, pred_wav_layers[-1], mixture )\n",
    "            sdr, _ = _SDR( mixture, source, pred_wav_layers[-1], num_spks )\n",
    "            #loss = loss1 + loss2 + loss3\n",
    "            #loss2 =  ( loss21 / num_spks  + loss22 / num_spks + loss23 / num_spks + loss24 / num_spks ) / num_stages  \n",
    "            #loss = ( loss1 + loss2 ) / 2\n",
    "            loss = (1-alpha) * loss1 + alpha * loss2\n",
    "            total_sisnri += loss3.item() / num_spks\n",
    "            total_sdr += sdr\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix({\"train loss\": loss.item() })\n",
    "            pbar.update()\n",
    "    print( \"learning rate:\", optimizer.param_groups[0]['lr'] )\n",
    "    print( \"epoch:\", epoch, \"train sisnri loss:\", total_sisnri / len( train_loader ), \" sdr:\", total_sdr / len( train_loader ) )\n",
    "    \n",
    "    total_sisnri = 0\n",
    "    total_sdr = 0\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(val_loader),\n",
    "              total=len(val_loader)) as pbar:\n",
    "        for step, (mixture, source) in pbar:\n",
    "            #source = source.permute( 1, 2, 0 )\n",
    "            mixture, source = mixture.to(device), source.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred_wav_layers = model(mixture)\n",
    "                #pred_wav = pred_wav.permute( 2, 0, 1 )\n",
    "                pred_wav_layers = pred_wav_layers.permute( 0, 3, 1, 2 )\n",
    "                loss1 = pit_sisnr_time( source, pred_wav_layers[-1] )\n",
    "                #loss21 = pit_sisnr_mag( source, pred_wav_layers[0], 0 )\n",
    "                #loss22 = pit_sisnr_mag( source, pred_wav_layers[1], 1 )\n",
    "                #loss23 = pit_sisnr_mag( source, pred_wav_layers[2], 2 )\n",
    "                #loss24 = pit_sisnr_mag( source, pred_wav, 3 )\n",
    "                loss2i = []\n",
    "                for idx, pred_wav_layer in enumerate( pred_wav_layers ):\n",
    "                    loss2i.append( pit_sisnr_mag( source, pred_wav_layer, idx ) )\n",
    "                loss2 = torch.mean( torch.stack(loss2i) / num_spks )\n",
    "                loss3, _ = pit_sisnri( source, pred_wav_layers[-1], mixture )\n",
    "                sdr, _ = _SDR( mixture, source, pred_wav_layers[-1], num_spks )\n",
    "                #loss2 =  ( loss21 / num_spks  + loss22 / num_spks + loss23 / num_spks + loss24 / num_spks ) / num_stages  \n",
    "                loss = (1-alpha) * loss1 + alpha * loss2\n",
    "                total_sisnri += loss3.item() /num_spks\n",
    "                total_sdr += sdr\n",
    "                total_loss += loss.item()\n",
    "            pbar.set_postfix({\"val loss\": loss.item() })\n",
    "            pbar.update()\n",
    "    val_loss = total_loss / len( val_loader )\n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_path = \"noav_my_model_training_state.pt\"\n",
    "        torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "             'loss': loss,            \n",
    "            },\n",
    "           save_path)\n",
    "    scheduler.step(val_loss)\n",
    "    print( \"epoch:\", epoch, \"val sisnri loss:\", total_sisnri / len( val_loader ), \" sdr:\", total_sdr / len( val_loader ) )\n",
    "    \n",
    "    total_sisnri = 0\n",
    "    total_sdr = 0\n",
    "    with tqdm(enumerate(test_loader),\n",
    "              total=len(test_loader)) as pbar:\n",
    "        for step, (mixture, source) in pbar:\n",
    "            #source = source.permute( 1, 2, 0 )\n",
    "            mixture, source = mixture.to(device), source.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred_wav_layers = model(mixture)\n",
    "                pred_wav_layers = pred_wav_layers.permute( 0, 3, 1, 2 )\n",
    "                loss3, _ = pit_sisnri( source, pred_wav_layers[-1], mixture )\n",
    "                sdr, _ = _SDR( mixture, source, pred_wav_layers[-1], num_spks )\n",
    "                total_sisnri += loss3.item() / num_spks\n",
    "                total_sdr += sdr\n",
    "            pbar.set_postfix({\"test loss\": loss.item() })\n",
    "            pbar.update()\n",
    "            if step == 0:\n",
    "                #print( \"size of pred_wav:\", pred_wav.size() )\n",
    "                write(\"./mix.wav\", rate=8000, data=mixture[0, :].cpu().detach().numpy())\n",
    "                write(\"./spk1.wav\", rate=8000, data=pred_wav_layers[-1,0,0,:].cpu().detach().numpy())\n",
    "                write(\"./spk2.wav\", rate=8000, data=pred_wav_layers[-1,1,0,:].cpu().detach().numpy())  \n",
    "                print( \"wav file was wrote.\" )\n",
    "    print( \"epoch:\", epoch, \"test sisnri loss:\", total_sisnri / len( test_loader ), \" sdr:\", total_sdr / len( test_loader ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d71db1-9505-47d5-9487-bee09263eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
